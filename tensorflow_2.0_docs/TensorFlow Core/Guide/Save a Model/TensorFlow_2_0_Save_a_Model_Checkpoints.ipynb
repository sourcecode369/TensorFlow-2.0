{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow 2.0 Save a Model - Checkpoints.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/TensorFlow-2.0/blob/master/tensorflow_2.0_docs/TensorFlow%20Core/Guide/Save%20a%20Model/TensorFlow_2_0_Save_a_Model_Checkpoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWTp_8ttpUJC",
        "colab_type": "text"
      },
      "source": [
        "### Install and importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEzalRPDYXNs",
        "colab_type": "code",
        "outputId": "3ec40128-f971-42bd-8bcb-d0ac0ffeb3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "%%time\n",
        "!pip install --upgrade tensorflow\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \",tf.__version__)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "TensorFlow version:  2.0.0\n",
            "CPU times: user 168 ms, sys: 29.1 ms, total: 197 ms\n",
            "Wall time: 8.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMGhgd6_aBvC",
        "colab_type": "text"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_-JId8kaD4x",
        "colab_type": "text"
      },
      "source": [
        "The phrase \"Saving a TensorFlow model\" typically means one of two things:\n",
        "\n",
        "1. Checkpoints, OR\n",
        "2. SavedModel.\n",
        "\n",
        "Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model and thus are typically only useful when source code that will use the saved parameter values is available.\n",
        "\n",
        "The SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint). Models in this format are independent of the source code that created the model. They are thus suitable for deployment via TensorFlow Serving, TensorFlow Lite, TensorFlow.js, or programs in other programming languages (the C, C++, Java, Go, Rust, C# etc. TensorFlow APIs).\n",
        "\n",
        "This guide covers APIs for writing and reading checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TyT1K_wZbrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sJ0cLcfZ4wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = tf.keras.layers.Dense(5)\n",
        "    def call(self, x):\n",
        "        return self.l1(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOzBquUZaWGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGZCh-FualKG",
        "colab_type": "text"
      },
      "source": [
        "### Saving from tf.keras training APIs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOp9mK_aW5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.save_weights('easy_checkpoints')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKEtKs2WaXhV",
        "colab_type": "text"
      },
      "source": [
        "### Writing Checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqef6RlwasDM",
        "colab_type": "text"
      },
      "source": [
        "#### Manual checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSLZ6c7aa6Ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toy_dataset():\n",
        "    inputs = tf.range(10.)[:, None]\n",
        "    labels = inputs * 5 + tf.range(5.)[None, :]\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(dict(x=inputs, y=labels)).shuffle(buffer_size=2).repeat(100).batch(2)\n",
        "    dataset = dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMQ23JwxbsP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(net, example, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        output = net(example['x'])\n",
        "        loss = tf.reduce_mean(tf.abs(output - example['y']))\n",
        "    variables = net.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrRgwnFNcYCv",
        "colab_type": "text"
      },
      "source": [
        "#### Create the checkpoint objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0KEnfKlcdMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWukLAdDoVeI",
        "colab_type": "text"
      },
      "source": [
        "#### Train and checkpoint the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPWCPEc9cwOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_checkpoint(net, manager):\n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "    if manager.latest_checkpoint:\n",
        "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "        print(\"Initializing from scratch.\")\n",
        "    \n",
        "    for example in toy_dataset():\n",
        "        loss = train_step(net, example, opt)\n",
        "        ckpt.step.assign_add(1)\n",
        "        if int(ckpt.step) % 10 == 0:\n",
        "            save_path = manager.save()\n",
        "            print(\"Saved checkpoint for step {}:{}\".format(int(ckpt.step), save_path))\n",
        "            print(\"Loss {:1.2f}\".format(loss.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt7tby_TdusH",
        "colab_type": "code",
        "outputId": "92d51456-31dc-46b3-ca11-f593b979ac1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_and_checkpoint(net, manager)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restored from ./tf_ckpts/ckpt-155\n",
            "Saved checkpoint for step 1560:./tf_ckpts/ckpt-156\n",
            "Loss 28.63\n",
            "Saved checkpoint for step 1570:./tf_ckpts/ckpt-157\n",
            "Loss 28.55\n",
            "Saved checkpoint for step 1580:./tf_ckpts/ckpt-158\n",
            "Loss 23.53\n",
            "Saved checkpoint for step 1590:./tf_ckpts/ckpt-159\n",
            "Loss 26.74\n",
            "Saved checkpoint for step 1600:./tf_ckpts/ckpt-160\n",
            "Loss 26.66\n",
            "Saved checkpoint for step 1610:./tf_ckpts/ckpt-161\n",
            "Loss 28.22\n",
            "Saved checkpoint for step 1620:./tf_ckpts/ckpt-162\n",
            "Loss 28.13\n",
            "Saved checkpoint for step 1630:./tf_ckpts/ckpt-163\n",
            "Loss 26.43\n",
            "Saved checkpoint for step 1640:./tf_ckpts/ckpt-164\n",
            "Loss 26.35\n",
            "Saved checkpoint for step 1650:./tf_ckpts/ckpt-165\n",
            "Loss 24.65\n",
            "Saved checkpoint for step 1660:./tf_ckpts/ckpt-166\n",
            "Loss 26.19\n",
            "Saved checkpoint for step 1670:./tf_ckpts/ckpt-167\n",
            "Loss 27.72\n",
            "Saved checkpoint for step 1680:./tf_ckpts/ckpt-168\n",
            "Loss 27.64\n",
            "Saved checkpoint for step 1690:./tf_ckpts/ckpt-169\n",
            "Loss 27.56\n",
            "Saved checkpoint for step 1700:./tf_ckpts/ckpt-170\n",
            "Loss 24.28\n",
            "Saved checkpoint for step 1710:./tf_ckpts/ckpt-171\n",
            "Loss 25.80\n",
            "Saved checkpoint for step 1720:./tf_ckpts/ckpt-172\n",
            "Loss 27.31\n",
            "Saved checkpoint for step 1730:./tf_ckpts/ckpt-173\n",
            "Loss 27.23\n",
            "Saved checkpoint for step 1740:./tf_ckpts/ckpt-174\n",
            "Loss 27.14\n",
            "Saved checkpoint for step 1750:./tf_ckpts/ckpt-175\n",
            "Loss 25.49\n",
            "Saved checkpoint for step 1760:./tf_ckpts/ckpt-176\n",
            "Loss 26.98\n",
            "Saved checkpoint for step 1770:./tf_ckpts/ckpt-177\n",
            "Loss 23.76\n",
            "Saved checkpoint for step 1780:./tf_ckpts/ckpt-178\n",
            "Loss 26.81\n",
            "Saved checkpoint for step 1790:./tf_ckpts/ckpt-179\n",
            "Loss 26.73\n",
            "Saved checkpoint for step 1800:./tf_ckpts/ckpt-180\n",
            "Loss 26.65\n",
            "Saved checkpoint for step 1810:./tf_ckpts/ckpt-181\n",
            "Loss 25.02\n",
            "Saved checkpoint for step 1820:./tf_ckpts/ckpt-182\n",
            "Loss 26.48\n",
            "Saved checkpoint for step 1830:./tf_ckpts/ckpt-183\n",
            "Loss 24.86\n",
            "Saved checkpoint for step 1840:./tf_ckpts/ckpt-184\n",
            "Loss 20.18\n",
            "Saved checkpoint for step 1850:./tf_ckpts/ckpt-185\n",
            "Loss 26.23\n",
            "Saved checkpoint for step 1860:./tf_ckpts/ckpt-186\n",
            "Loss 24.62\n",
            "Saved checkpoint for step 1870:./tf_ckpts/ckpt-187\n",
            "Loss 23.02\n",
            "Saved checkpoint for step 1880:./tf_ckpts/ckpt-188\n",
            "Loss 21.43\n",
            "Saved checkpoint for step 1890:./tf_ckpts/ckpt-189\n",
            "Loss 22.88\n",
            "Saved checkpoint for step 1900:./tf_ckpts/ckpt-190\n",
            "Loss 25.82\n",
            "Saved checkpoint for step 1910:./tf_ckpts/ckpt-191\n",
            "Loss 19.72\n",
            "Saved checkpoint for step 1920:./tf_ckpts/ckpt-192\n",
            "Loss 21.15\n",
            "Saved checkpoint for step 1930:./tf_ckpts/ckpt-193\n",
            "Loss 19.59\n",
            "Saved checkpoint for step 1940:./tf_ckpts/ckpt-194\n",
            "Loss 25.49\n",
            "Saved checkpoint for step 1950:./tf_ckpts/ckpt-195\n",
            "Loss 20.95\n",
            "Saved checkpoint for step 1960:./tf_ckpts/ckpt-196\n",
            "Loss 23.84\n",
            "Saved checkpoint for step 1970:./tf_ckpts/ckpt-197\n",
            "Loss 23.76\n",
            "Saved checkpoint for step 1980:./tf_ckpts/ckpt-198\n",
            "Loss 25.16\n",
            "Saved checkpoint for step 1990:./tf_ckpts/ckpt-199\n",
            "Loss 23.61\n",
            "Saved checkpoint for step 2000:./tf_ckpts/ckpt-200\n",
            "Loss 23.53\n",
            "Saved checkpoint for step 2010:./tf_ckpts/ckpt-201\n",
            "Loss 24.91\n",
            "Saved checkpoint for step 2020:./tf_ckpts/ckpt-202\n",
            "Loss 24.83\n",
            "Saved checkpoint for step 2030:./tf_ckpts/ckpt-203\n",
            "Loss 21.84\n",
            "Saved checkpoint for step 2040:./tf_ckpts/ckpt-204\n",
            "Loss 21.77\n",
            "Saved checkpoint for step 2050:./tf_ckpts/ckpt-205\n",
            "Loss 24.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDYG8KxVoOyO",
        "colab_type": "text"
      },
      "source": [
        "#### Restore and continue training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWbEET_BdxkH",
        "colab_type": "code",
        "outputId": "44ae99fc-c74d-4de2-a707-36a09780d457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(0.1)\n",
        "net = Net()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net)\n",
        "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
        "\n",
        "train_and_checkpoint(net, manager)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restored from ./tf_ckpts/ckpt-205\n",
            "Saved checkpoint for step 2060:./tf_ckpts/ckpt-206\n",
            "Loss 21.62\n",
            "Saved checkpoint for step 2070:./tf_ckpts/ckpt-207\n",
            "Loss 20.11\n",
            "Saved checkpoint for step 2080:./tf_ckpts/ckpt-208\n",
            "Loss 21.47\n",
            "Saved checkpoint for step 2090:./tf_ckpts/ckpt-209\n",
            "Loss 24.25\n",
            "Saved checkpoint for step 2100:./tf_ckpts/ckpt-210\n",
            "Loss 19.90\n",
            "Saved checkpoint for step 2110:./tf_ckpts/ckpt-211\n",
            "Loss 24.09\n",
            "Saved checkpoint for step 2120:./tf_ckpts/ckpt-212\n",
            "Loss 24.01\n",
            "Saved checkpoint for step 2130:./tf_ckpts/ckpt-213\n",
            "Loss 23.92\n",
            "Saved checkpoint for step 2140:./tf_ckpts/ckpt-214\n",
            "Loss 23.84\n",
            "Saved checkpoint for step 2150:./tf_ckpts/ckpt-215\n",
            "Loss 23.76\n",
            "Saved checkpoint for step 2160:./tf_ckpts/ckpt-216\n",
            "Loss 23.68\n",
            "Saved checkpoint for step 2170:./tf_ckpts/ckpt-217\n",
            "Loss 22.20\n",
            "Saved checkpoint for step 2180:./tf_ckpts/ckpt-218\n",
            "Loss 23.51\n",
            "Saved checkpoint for step 2190:./tf_ckpts/ckpt-219\n",
            "Loss 20.66\n",
            "Saved checkpoint for step 2200:./tf_ckpts/ckpt-220\n",
            "Loss 23.35\n",
            "Saved checkpoint for step 2210:./tf_ckpts/ckpt-221\n",
            "Loss 20.52\n",
            "Saved checkpoint for step 2220:./tf_ckpts/ckpt-222\n",
            "Loss 23.18\n",
            "Saved checkpoint for step 2230:./tf_ckpts/ckpt-223\n",
            "Loss 19.00\n",
            "Saved checkpoint for step 2240:./tf_ckpts/ckpt-224\n",
            "Loss 21.66\n",
            "Saved checkpoint for step 2250:./tf_ckpts/ckpt-225\n",
            "Loss 22.94\n",
            "Saved checkpoint for step 2260:./tf_ckpts/ckpt-226\n",
            "Loss 21.50\n",
            "Saved checkpoint for step 2270:./tf_ckpts/ckpt-227\n",
            "Loss 16.02\n",
            "Saved checkpoint for step 2280:./tf_ckpts/ckpt-228\n",
            "Loss 20.00\n",
            "Saved checkpoint for step 2290:./tf_ckpts/ckpt-229\n",
            "Loss 21.27\n",
            "Saved checkpoint for step 2300:./tf_ckpts/ckpt-230\n",
            "Loss 21.19\n",
            "Saved checkpoint for step 2310:./tf_ckpts/ckpt-231\n",
            "Loss 18.45\n",
            "Saved checkpoint for step 2320:./tf_ckpts/ckpt-232\n",
            "Loss 21.03\n",
            "Saved checkpoint for step 2330:./tf_ckpts/ckpt-233\n",
            "Loss 19.63\n",
            "Saved checkpoint for step 2340:./tf_ckpts/ckpt-234\n",
            "Loss 22.20\n",
            "Saved checkpoint for step 2350:./tf_ckpts/ckpt-235\n",
            "Loss 22.12\n",
            "Saved checkpoint for step 2360:./tf_ckpts/ckpt-236\n",
            "Loss 20.72\n",
            "Saved checkpoint for step 2370:./tf_ckpts/ckpt-237\n",
            "Loss 20.65\n",
            "Saved checkpoint for step 2380:./tf_ckpts/ckpt-238\n",
            "Loss 21.87\n",
            "Saved checkpoint for step 2390:./tf_ckpts/ckpt-239\n",
            "Loss 20.49\n",
            "Saved checkpoint for step 2400:./tf_ckpts/ckpt-240\n",
            "Loss 21.71\n",
            "Saved checkpoint for step 2410:./tf_ckpts/ckpt-241\n",
            "Loss 21.63\n",
            "Saved checkpoint for step 2420:./tf_ckpts/ckpt-242\n",
            "Loss 21.55\n",
            "Saved checkpoint for step 2430:./tf_ckpts/ckpt-243\n",
            "Loss 20.18\n",
            "Saved checkpoint for step 2440:./tf_ckpts/ckpt-244\n",
            "Loss 21.39\n",
            "Saved checkpoint for step 2450:./tf_ckpts/ckpt-245\n",
            "Loss 16.21\n",
            "Saved checkpoint for step 2460:./tf_ckpts/ckpt-246\n",
            "Loss 18.69\n",
            "Saved checkpoint for step 2470:./tf_ckpts/ckpt-247\n",
            "Loss 19.88\n",
            "Saved checkpoint for step 2480:./tf_ckpts/ckpt-248\n",
            "Loss 21.06\n",
            "Saved checkpoint for step 2490:./tf_ckpts/ckpt-249\n",
            "Loss 20.98\n",
            "Saved checkpoint for step 2500:./tf_ckpts/ckpt-250\n",
            "Loss 19.65\n",
            "Saved checkpoint for step 2510:./tf_ckpts/ckpt-251\n",
            "Loss 19.57\n",
            "Saved checkpoint for step 2520:./tf_ckpts/ckpt-252\n",
            "Loss 17.01\n",
            "Saved checkpoint for step 2530:./tf_ckpts/ckpt-253\n",
            "Loss 19.42\n",
            "Saved checkpoint for step 2540:./tf_ckpts/ckpt-254\n",
            "Loss 19.34\n",
            "Saved checkpoint for step 2550:./tf_ckpts/ckpt-255\n",
            "Loss 19.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_lcWp4MetG4",
        "colab_type": "code",
        "outputId": "9130ba17-a66b-4451-cf3d-32e7526a0a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "manager.checkpoints"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./tf_ckpts/ckpt-253', './tf_ckpts/ckpt-254', './tf_ckpts/ckpt-255']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_OC1qGce_tw",
        "colab_type": "code",
        "outputId": "e8f5874d-da4c-40cf-b87b-862096ed8e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "!ls ./tf_ckpts/"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t      ckpt-254.data-00000-of-00001  ckpt-255.index\n",
            "ckpt-253.data-00000-of-00001  ckpt-254.index\n",
            "ckpt-253.index\t\t      ckpt-255.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqXq5Q4-fiA4",
        "colab_type": "text"
      },
      "source": [
        "### Loading Mechanics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPhC0PEgpOrp",
        "colab_type": "code",
        "outputId": "2514d9a8-8ddb-47d7-fa00-37c1711be888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "to_restore = tf.Variable(tf.zeros([5]))\n",
        "print(to_restore.numpy())\n",
        "fake_layer = tf.train.Checkpoint(bias=to_restore)\n",
        "fake_net = tf.train.Checkpoint(l1=fake_layer)\n",
        "new_root = tf.train.Checkpoint(net=fake_net)\n",
        "status = new_root.restore(tf.train.latest_checkpoint('./tf_ckpts/'))\n",
        "print(to_restore.numpy())"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0.]\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).step\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).net.l1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.l1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).net.l1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.l1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).net.l1.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "[2.23092   2.321593  2.4531858 2.5489972 2.5489972]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMewYnQcr2aR",
        "colab_type": "code",
        "outputId": "80b69755-8e0b-4519-be9c-22f2676a2238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "status.assert_existing_objects_matched()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f82096f6908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT8_oBB8sM-O",
        "colab_type": "text"
      },
      "source": [
        "#### Delayed restorations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyUScFjusYRF",
        "colab_type": "code",
        "outputId": "8ae23784-4668-4e60-eb0d-2647c4aef9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "delayed_restore = tf.Variable(tf.zeros([1,5]))\n",
        "print(delayed_restore.numpy())\n",
        "fake_layer.kernel = delayed_restore\n",
        "print(delayed_restore.numpy())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0.]]\n",
            "[[3.1211607 1.8763008 2.483833  2.207475  3.0152123]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivpH5e7KszOM",
        "colab_type": "text"
      },
      "source": [
        "#### Manually inspecting checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUw08cY2s4j0",
        "colab_type": "code",
        "outputId": "7c1d31ca-e786-48e2-e0fc-c03298d3f50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "tf.train.list_variables(tf.train.latest_checkpoint('./tf_ckpts/'))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
              " ('net/l1/bias/.ATTRIBUTES/VARIABLE_VALUE', [5]),\n",
              " ('net/l1/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [5]),\n",
              " ('net/l1/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [5]),\n",
              " ('net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE', [1, 5]),\n",
              " ('net/l1/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
              "  [1, 5]),\n",
              " ('net/l1/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
              "  [1, 5]),\n",
              " ('optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
              " ('optimizer/beta_2/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
              " ('optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
              " ('optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
              " ('optimizer/learning_rate/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
              " ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', []),\n",
              " ('step/.ATTRIBUTES/VARIABLE_VALUE', [])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJDLjSDvs86k",
        "colab_type": "text"
      },
      "source": [
        "#### List and disctionary tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InAsdvVNtC-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save = tf.train.Checkpoint()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkRBIb3wtQEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save.listed = [tf.Variable(1.)]\n",
        "save.listed.append(tf.Variable(2.))\n",
        "save.mapped = {'one':save.listed[0]}\n",
        "save.mapped[\"two\"] = save.listed[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG0xocXftQcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = save.save(\"./tf_list_example\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTPG5Vujtm7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "restore = tf.train.Checkpoint()\n",
        "v2 = tf.Variable(0.)\n",
        "assert 0. == v2.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7owa8TDtter",
        "colab_type": "code",
        "outputId": "f644f3fe-0ce0-4b7e-decf-de46ffa4d326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "restore.mapped = {'two':v2}\n",
        "restore.restore(save_path)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f82096f1c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXL1Y7tpt1-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert 2. == v2.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMavoCVqt4li",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c1b0b298-169e-4b54-89c4-699ead041a34"
      },
      "source": [
        "restore.listed = []\n",
        "print(restore.listed)  \n",
        "v1 = tf.Variable(0.)\n",
        "restore.listed.append(v1)\n",
        "assert 1. == v1.numpy()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ListWrapper([])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTt0XnYG8G-p",
        "colab_type": "text"
      },
      "source": [
        "### Saving object-based checkpoints with Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIRGyfN8Pe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf_compat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgz8Az5W8UJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "d6d6904c-cbcf-4a22-b82c-21d322f943e4"
      },
      "source": [
        "def model_fn(features, labels, mode):\n",
        "    net = Net()\n",
        "    opt = tf.keras.optimizers.Adam(0.1)\n",
        "    ckpt = tf.train.Checkpoint(step=tf_compat.train.get_global_step(),\n",
        "                               optimizer=opt, net=net)\n",
        "    with tf.GradientTape() as tape:\n",
        "        output = net(features['x'])\n",
        "        loss = tf.reduce_mean(tf.abs(output - features['y']))\n",
        "    variables = net.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode, \n",
        "        loss = loss,\n",
        "        train_op = tf.group(opt.apply_gradients(zip(gradients, variables)),\n",
        "                            ckpt.step.assign_add(1)),\n",
        "                            scaffold = tf_compat.train.Scaffold(saver=ckpt)\n",
        "    )\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "est = tf.estimator.Estimator(model_fn, './tf_estimator_example/')\n",
        "est.train(toy_dataset, steps=10)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './tf_estimator_example/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f820990b518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./tf_estimator_example/model.ckpt.\n",
            "INFO:tensorflow:loss = 4.370314, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 10 into ./tf_estimator_example/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 34.59539.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7f820990b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-C0T-4s97MR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e8b42cda-f223-49b5-835f-214716d29b56"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(0.1)\n",
        "net = Net()\n",
        "ckpt = tf.train.Checkpoint(\n",
        "    step = tf.Variable(1, dtype=tf.int64), optimizer=opt, net = net\n",
        ")\n",
        "ckpt.restore(tf.train.latest_checkpoint('./tf_estimtor_example/'))\n",
        "ckpt.step.numpy()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmQ34ef_-ZZG",
        "colab_type": "text"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRNTQ22R-e63",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow objects provide an easy automatic mechanism for saving and restoring the values of variables they use.\n",
        "\n"
      ]
    }
  ]
}